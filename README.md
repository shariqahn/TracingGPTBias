# Interpreting and Editing Dialect Prejudice in GPT

This investigation aims to unpack the black-box nature of machine learning models. It focuses on exploring how these systems store racial biases and stereotypes through an analysis of dialect prejudice. This will is analyzed via a causal tracing and logit difference methodology. We also explore rectifying biases through causal tracing and model editing to update model logic and knowledge. This work is intended to explore the internals of large language models as well as potential solutions for mitigating biases within them. For more details, see [the report](./Tracing_Bias.pdf)